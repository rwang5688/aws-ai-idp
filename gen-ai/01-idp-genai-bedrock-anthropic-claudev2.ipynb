{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f6e38fc-9f24-4c8f-9e2e-2c120eb68d45",
   "metadata": {},
   "source": [
    "# Augment Intelligent Document Processing with generative AI using Amazon Bedrock\n",
    "---\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> \n",
    "    <b>NOTE:</b> You will need to use a Jupyter Kernel with Python 3.9 or above to use this notebook. If you are in Amazon SageMaker Studio, you can use the `Data Science 3.0` image.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"> \n",
    "    <b>NOTE:</b> You will need 3rd party model access to Anthropic Claude V1 model to be able to run this notebook. Verify if you have access to the model by going to <a href=\"https://console.aws.amazon.com/bedrock\" target=\"_blank\">Amazon Bedrock console</a> > left menu \"Model access\". The \"Access status\" for Anthropic Claude must be in \"Access granted\" status in green. If you do not have access, then click \"Edit\" button on the top right > select the model checkbox > click \"Save changes\" button at the bottom. You should have access to the model within a few moments.\n",
    "</div>\n",
    "\n",
    "In this notebook, we demonstrate how you can integrate Amazon Textract with LangChain as a document loader to extract data from documents and use generative AI capabilities within the various IDP phases. We will perform the following with different LLMs.\n",
    "\n",
    "- Classification\n",
    "- Summarization\n",
    "- Standardization\n",
    "- Spell check corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c12c62-2259-48b9-8148-70a540c28ae5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -U boto3 langchain faiss-cpu sagemaker setuptools transformers\n",
    "!pip install amazon-textract-textractor pypdf Pillow transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bd886e-d953-4b0e-81a1-54d72847b8f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "# if you wish to run this notebook outside of SageMaker Studio, comment out the below line\n",
    "#role = sagemaker.get_execution_role()\n",
    "# if you wish to run this notebook outside of SageMaker Studio, uncomment the following line\n",
    "role = \"arn:aws:iam::793803570670:role/SageMakerExecutionRole-20230814\"\n",
    "data_bucket = sagemaker.Session().default_bucket()\n",
    "bedrock = boto3.client('bedrock-runtime')\n",
    "s3 = boto3.client(\"s3\")\n",
    "print(f\"SageMaker bucket is {data_bucket}, and SageMaker Execution Role is {role}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3b0ee4-b856-4718-992e-99390f56068e",
   "metadata": {},
   "source": [
    "## 1. Classification\n",
    "---\n",
    "\n",
    "Classify a document based on it's content, given a list of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5641327d-e375-4c03-ac1e-96704bcdbd89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import AmazonTextractPDFLoader\n",
    "from langchain.llms import Bedrock\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "loader = AmazonTextractPDFLoader(\"./samples/discharge-summary.png\")\n",
    "document = loader.load()\n",
    "\n",
    "template = \"\"\"\n",
    "\n",
    "Given a list of classes, classify the document into one of these classes. Skip any preamble text and just give the class name.\n",
    "\n",
    "<classes>DISCHARGE_SUMMARY, RECEIPT, PRESCRIPTION</classes>\n",
    "<document>{doc_text}<document>\n",
    "<classification>\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"doc_text\"])\n",
    "bedrock_llm = Bedrock(client=bedrock, model_id=\"anthropic.claude-v2\")\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=bedrock_llm)\n",
    "class_name = llm_chain.invoke(document[0].page_content)[\"text\"]\n",
    "\n",
    "print(f\"The provided document is = {class_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed904147-9ed1-4db1-81ee-5a433624b204",
   "metadata": {},
   "source": [
    "## 2. Summarization\n",
    "---\n",
    "\n",
    "Summarize large pieces of text from a document into smaller, more coincise explanations. In this block we will perform a single page summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4212bb6d-9069-4f34-a684-4d7d1750e6a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import AmazonTextractPDFLoader\n",
    "from langchain.llms import Bedrock\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "loader = AmazonTextractPDFLoader(\"./samples/discharge-summary.png\")\n",
    "document = loader.load()\n",
    "\n",
    "template = \"\"\"\n",
    "\n",
    "Given a full document, give me a concise summary. Skip any preamble text and just give the summary.\n",
    "\n",
    "<document>{doc_text}</document>\n",
    "<summary>\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"doc_text\"])\n",
    "bedrock_llm = Bedrock(client=bedrock, model_id=\"anthropic.claude-v2\")\n",
    "\n",
    "num_tokens = bedrock_llm.get_num_tokens(document[0].page_content)\n",
    "print (f\"Our prompt has {num_tokens} tokens \\n\\n=========================\\n\")\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=bedrock_llm)\n",
    "summary = llm_chain.invoke(document[0].page_content)[\"text\"]\n",
    "\n",
    "print(summary.replace(\"</summary>\",\"\").strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae4d20a-eef5-4147-ac82-647ee44ed467",
   "metadata": {},
   "source": [
    "### Multi-page summarization\n",
    "\n",
    "We will now attempt to summarize a multi-page document. In order to extract a multi-page PDF we first need to upload it to an S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c032d517-9601-4d9e-bf36-1608b8355488",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws s3 cp ./samples/health_plan.pdf s3://{data_bucket}/bedrock-sample/health_plan.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe00801-d6a5-4b14-85f4-f403d3ec3b02",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import AmazonTextractPDFLoader\n",
    "from langchain.llms import Bedrock\n",
    "\n",
    "bedrock_llm = Bedrock(client=bedrock, model_id=\"anthropic.claude-v2\")\n",
    "\n",
    "loader = AmazonTextractPDFLoader(f\"s3://{data_bucket}/bedrock-sample/health_plan.pdf\")\n",
    "document = loader.load()\n",
    "\n",
    "document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befeda3c-1608-4b4f-9625-c02771cfe202",
   "metadata": {},
   "source": [
    "Amazon Textract PDF Loader module has returned per page text. Since with 100k context we have a pretty healthy context window we don't need to further split this. Let's see the per page token size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4adaa45-cd1d-4687-9911-50d7fa53b488",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_docs = len(document)\n",
    "print (f\"There are {num_docs} pages in the document\")\n",
    "for index, doc in enumerate(document):\n",
    "    num_tokens_first_doc = bedrock_llm.get_num_tokens(doc.page_content)\n",
    "    print (f\"Page {index+1} has approx. {num_tokens_first_doc} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e988e759-4249-4166-b49b-921ec5f2ad12",
   "metadata": {},
   "source": [
    "We will use LangChain `load_summarize_chain` with a `map_reduce` chain type. For more information on Summarization techniques with LangChain refer to [this document](https://python.langchain.com/docs/use_cases/summarization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d771fcf9-a7af-4161-bdb7-f605c4a4f5ed",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "summary_chain = load_summarize_chain(llm=bedrock_llm, chain_type='map_reduce',\n",
    "                                     verbose=True # Set verbose=True if you want to see the prompts being used\n",
    "                                    )\n",
    "output = summary_chain.invoke(document)[\"output_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cca6a42-918a-4935-b237-59e2dc1fb477",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(output.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac62d59-5a42-4546-b26a-641db1992cfc",
   "metadata": {},
   "source": [
    "## 3. Standardization\n",
    "---\n",
    "\n",
    "Let's try to standardize dates from our discharge summary document. Note that the document has dates in `DD-MON-YYYY` format, and we want to convert all of those dates to `MM/DD/YYYY` format. We will use simple prompt engineering techniques to show Claude some example and have it generate the output in a JSON format (Key value pair)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1f1f72-4c9c-4f7e-ad10-0e85bf69d509",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import AmazonTextractPDFLoader\n",
    "from langchain.llms import Bedrock\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "loader = AmazonTextractPDFLoader(\"./samples/discharge-summary.png\")\n",
    "document = loader.load()\n",
    "\n",
    "bedrock_llm = Bedrock(client=bedrock, model_id=\"anthropic.claude-v2\")\n",
    "\n",
    "template1 = \"\"\"\n",
    "\n",
    "Given a full document, answer the question and format the output in the format specified. Skip any preamble text and just generate the JSON.\n",
    "\n",
    "<format>\n",
    "{{\n",
    "  \"key_name\":\"key_value\"\n",
    "}}\n",
    "</format>\n",
    "<document>{doc_text}</document>\n",
    "<question>{question}</question>\"\"\"\n",
    "\n",
    "template2 = \"\"\"\n",
    "\n",
    "Given a JSON document, format the dates in the value fields precisely in the provided format. Skip any preamble text and just generate the JSON.\n",
    "\n",
    "<format>DD/MM/YYYY</format>\n",
    "<json_document>{json_doc}</json_document>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt1 = PromptTemplate(template=template1, input_variables=[\"doc_text\", \"question\"])\n",
    "llm_chain = LLMChain(prompt=prompt1, llm=bedrock_llm, verbose=True)\n",
    "\n",
    "prompt2 = PromptTemplate(template=template2, input_variables=[\"json_doc\"])\n",
    "llm_chain2 = LLMChain(prompt=prompt2, llm=bedrock_llm, verbose=True)\n",
    "\n",
    "chain = ( \n",
    "    llm_chain \n",
    "    | {'json_doc': lambda x: x['text'] }  \n",
    "    | llm_chain2\n",
    ")\n",
    "\n",
    "std_op = chain.invoke({ \"doc_text\": document[0].page_content, \n",
    "                        \"question\": \"Can you give me the patient admitted and discharge dates?\"})\n",
    "\n",
    "print(std_op['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c53095-d4ed-4732-9846-e8e427d01711",
   "metadata": {},
   "source": [
    "And we get a nicely formatted JSON output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b249e4-8028-4998-8d4a-7f72d7855b38",
   "metadata": {},
   "source": [
    "## 4. Spell check and corrections\n",
    "---\n",
    "\n",
    "Perform grammatical and spelling corrections on text extracted from a hand written document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e3bd16-665a-4cd1-b520-46bfb39e0736",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import AmazonTextractPDFLoader\n",
    "from langchain.llms import Bedrock\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "loader = AmazonTextractPDFLoader(\"./samples/hand_written_note.pdf\")\n",
    "document = loader.load()\n",
    "\n",
    "template = \"\"\"\n",
    "\n",
    "Given a detailed 'Document', perform spelling and grammatical corrections. Ensure the output is coherent, polished, and free from errors. Skip any preamble text and give the answer.\n",
    "\n",
    "<document>{doc_text}</<document>\n",
    "<answer>\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"doc_text\"])\n",
    "llm = Bedrock(client=bedrock, model_id=\"anthropic.claude-v2\")\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "try:\n",
    "    txt = document[0].page_content\n",
    "    std_op = llm_chain.invoke({\"doc_text\": txt})[\"text\"]\n",
    "    \n",
    "    print(\"Extracted text\")\n",
    "    print(\"==============\")\n",
    "    print(txt)\n",
    "\n",
    "    print(\"\\nCorrected text\")\n",
    "    print(\"==============\")\n",
    "    print(std_op.replace(\"</answer>\",\"\").strip())\n",
    "    print(\"\\n\")\n",
    "except Exception as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497cb636-9ea2-4f3f-aa6e-a856574a2a17",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "---\n",
    "Let's delete the pdf file we uploaded earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc2d322-c0b9-4eec-b544-edf6d761b15b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws s3api delete-object --bucket {data_bucket} --key bedrock-sample/health_plan.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969fbd21-e126-4bde-9907-29d30ec0c9bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
